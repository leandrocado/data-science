{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5QEyByP8f0oo"
   },
   "outputs": [],
   "source": [
    "#!unzip leapGestRecog.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZOw5sMMIoENr"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize(32),\n",
    "                                transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "alldataset = torchvision.datasets.ImageFolder(root='./leapGestRecog/00', transform=transform)\n",
    "\n",
    "for i in range(1, 10):\n",
    "    folder = torchvision.datasets.ImageFolder(root='./leapGestRecog/0{}'.format(i), transform=transform)\n",
    "    alldataset = torch.utils.data.ConcatDataset([alldataset, folder])\n",
    "    \n",
    "num_train = len(alldataset)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(0.1 * num_train))\n",
    "\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_idx, test_idx = indices[split:], indices[:split]\n",
    "train_idx, valid_idx = train_idx[split:], train_idx[:split]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "test_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    alldataset, batch_size=4, sampler=train_sampler,\n",
    "    num_workers=2\n",
    ")\n",
    "validloader = torch.utils.data.DataLoader(\n",
    "    alldataset, batch_size=4, sampler=valid_sampler,\n",
    "    num_workers=2\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    alldataset, batch_size=4, sampler=test_sampler,\n",
    "    num_workers=2\n",
    ")\n",
    "\n",
    "classes = ('01_palm', '02_l', '03_fist', '04_fist_moved',\n",
    "           '05_thumb', '06_index', '07_ok', '08_palm_moved', '09_c', '10_down')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "n90JSpuloYuR",
    "outputId": "23eb49a9-2a81-4e15-fd8e-b4eca789a3b0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAABFCAYAAABE+y1cAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "07_ok 03_fist 06_index  02_l\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "glWomJ_GsumD",
    "outputId": "c1fee796-c081-49e0-b416-2a53e06b89ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Vb6p-RXwqW2X",
    "outputId": "e89107f5-b262-4c90-82a3-a654c286b074"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = models.resnet50(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "DMLQdHBvqYMp",
    "outputId": "ee75cc7b-f7f9-4276-cee1-a3953cd1cf35"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=10, bias=True)\n",
       "    (4): LogSoftmax()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Freeze parameters so we don't backprop through them\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "model.fc = nn.Sequential(nn.Linear(2048, 512),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.2),\n",
    "                                 nn.Linear(512, 10),\n",
    "                                 nn.LogSoftmax(dim=1))\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.003)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Ka-Lc5hIqceN",
    "outputId": "82ce33f3-ca21-4ab0-b5c0-a527e67fe4bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5.. Train loss: 4.580.. Test loss: 3.253.. Test accuracy: 0.197\n",
      "Epoch 1/5.. Train loss: 2.263.. Test loss: 2.514.. Test accuracy: 0.214\n",
      "Epoch 1/5.. Train loss: 2.025.. Test loss: 2.477.. Test accuracy: 0.300\n",
      "Epoch 1/5.. Train loss: 2.037.. Test loss: 2.218.. Test accuracy: 0.303\n",
      "Epoch 1/5.. Train loss: 1.564.. Test loss: 2.724.. Test accuracy: 0.221\n",
      "Epoch 1/5.. Train loss: 1.860.. Test loss: 1.975.. Test accuracy: 0.444\n",
      "Epoch 1/5.. Train loss: 1.576.. Test loss: 1.616.. Test accuracy: 0.472\n",
      "Epoch 1/5.. Train loss: 1.211.. Test loss: 1.496.. Test accuracy: 0.565\n",
      "Epoch 1/5.. Train loss: 1.363.. Test loss: 1.017.. Test accuracy: 0.676\n",
      "Epoch 1/5.. Train loss: 1.281.. Test loss: 1.068.. Test accuracy: 0.672\n",
      "Epoch 1/5.. Train loss: 1.511.. Test loss: 0.637.. Test accuracy: 0.834\n",
      "Epoch 1/5.. Train loss: 1.398.. Test loss: 0.750.. Test accuracy: 0.762\n",
      "Epoch 1/5.. Train loss: 0.722.. Test loss: 0.914.. Test accuracy: 0.719\n",
      "Epoch 1/5.. Train loss: 1.541.. Test loss: 0.664.. Test accuracy: 0.784\n",
      "Epoch 1/5.. Train loss: 1.212.. Test loss: 0.591.. Test accuracy: 0.821\n",
      "Epoch 1/5.. Train loss: 1.137.. Test loss: 0.828.. Test accuracy: 0.754\n",
      "Epoch 1/5.. Train loss: 1.491.. Test loss: 0.622.. Test accuracy: 0.802\n",
      "Epoch 1/5.. Train loss: 1.430.. Test loss: 0.648.. Test accuracy: 0.821\n",
      "Epoch 1/5.. Train loss: 1.230.. Test loss: 0.452.. Test accuracy: 0.903\n",
      "Epoch 1/5.. Train loss: 1.411.. Test loss: 0.422.. Test accuracy: 0.915\n",
      "Epoch 1/5.. Train loss: 1.088.. Test loss: 0.434.. Test accuracy: 0.873\n",
      "Epoch 1/5.. Train loss: 0.629.. Test loss: 0.357.. Test accuracy: 0.911\n",
      "Epoch 1/5.. Train loss: 1.402.. Test loss: 0.392.. Test accuracy: 0.892\n",
      "Epoch 1/5.. Train loss: 0.909.. Test loss: 0.349.. Test accuracy: 0.921\n",
      "Epoch 1/5.. Train loss: 0.944.. Test loss: 0.328.. Test accuracy: 0.915\n",
      "Epoch 1/5.. Train loss: 1.237.. Test loss: 0.505.. Test accuracy: 0.869\n",
      "Epoch 1/5.. Train loss: 0.762.. Test loss: 0.466.. Test accuracy: 0.852\n",
      "Epoch 1/5.. Train loss: 1.007.. Test loss: 0.459.. Test accuracy: 0.870\n",
      "Epoch 1/5.. Train loss: 0.724.. Test loss: 0.230.. Test accuracy: 0.945\n",
      "Epoch 1/5.. Train loss: 0.923.. Test loss: 0.377.. Test accuracy: 0.901\n",
      "Epoch 1/5.. Train loss: 1.035.. Test loss: 0.549.. Test accuracy: 0.839\n",
      "Epoch 1/5.. Train loss: 0.834.. Test loss: 0.386.. Test accuracy: 0.887\n",
      "Epoch 1/5.. Train loss: 1.066.. Test loss: 0.368.. Test accuracy: 0.886\n",
      "Epoch 1/5.. Train loss: 0.808.. Test loss: 0.245.. Test accuracy: 0.941\n",
      "Epoch 1/5.. Train loss: 0.678.. Test loss: 0.321.. Test accuracy: 0.905\n",
      "Epoch 1/5.. Train loss: 0.853.. Test loss: 0.329.. Test accuracy: 0.899\n",
      "Epoch 1/5.. Train loss: 1.171.. Test loss: 0.217.. Test accuracy: 0.936\n",
      "Epoch 1/5.. Train loss: 1.131.. Test loss: 0.912.. Test accuracy: 0.752\n",
      "Epoch 1/5.. Train loss: 1.145.. Test loss: 0.453.. Test accuracy: 0.866\n",
      "Epoch 1/5.. Train loss: 1.194.. Test loss: 0.400.. Test accuracy: 0.881\n",
      "Epoch 1/5.. Train loss: 0.729.. Test loss: 0.334.. Test accuracy: 0.897\n",
      "Epoch 1/5.. Train loss: 0.833.. Test loss: 0.224.. Test accuracy: 0.953\n",
      "Epoch 1/5.. Train loss: 0.944.. Test loss: 0.263.. Test accuracy: 0.939\n",
      "Epoch 1/5.. Train loss: 0.906.. Test loss: 0.292.. Test accuracy: 0.910\n",
      "Epoch 1/5.. Train loss: 0.878.. Test loss: 0.374.. Test accuracy: 0.892\n",
      "Epoch 1/5.. Train loss: 0.537.. Test loss: 0.303.. Test accuracy: 0.920\n",
      "Epoch 1/5.. Train loss: 0.779.. Test loss: 0.393.. Test accuracy: 0.885\n",
      "Epoch 1/5.. Train loss: 1.199.. Test loss: 0.203.. Test accuracy: 0.948\n",
      "Epoch 1/5.. Train loss: 0.603.. Test loss: 0.357.. Test accuracy: 0.900\n",
      "Epoch 1/5.. Train loss: 0.793.. Test loss: 0.226.. Test accuracy: 0.939\n",
      "Epoch 2/5.. Train loss: 0.922.. Test loss: 0.197.. Test accuracy: 0.947\n",
      "Epoch 2/5.. Train loss: 0.900.. Test loss: 0.222.. Test accuracy: 0.939\n",
      "Epoch 2/5.. Train loss: 0.609.. Test loss: 0.212.. Test accuracy: 0.938\n",
      "Epoch 2/5.. Train loss: 0.811.. Test loss: 0.247.. Test accuracy: 0.924\n",
      "Epoch 2/5.. Train loss: 0.422.. Test loss: 0.224.. Test accuracy: 0.934\n",
      "Epoch 2/5.. Train loss: 1.041.. Test loss: 0.269.. Test accuracy: 0.918\n",
      "Epoch 2/5.. Train loss: 0.953.. Test loss: 0.413.. Test accuracy: 0.862\n",
      "Epoch 2/5.. Train loss: 0.679.. Test loss: 0.235.. Test accuracy: 0.931\n",
      "Epoch 2/5.. Train loss: 1.132.. Test loss: 0.279.. Test accuracy: 0.921\n",
      "Epoch 2/5.. Train loss: 0.706.. Test loss: 0.298.. Test accuracy: 0.916\n",
      "Epoch 2/5.. Train loss: 0.861.. Test loss: 0.594.. Test accuracy: 0.828\n",
      "Epoch 2/5.. Train loss: 0.635.. Test loss: 0.607.. Test accuracy: 0.834\n",
      "Epoch 2/5.. Train loss: 0.750.. Test loss: 0.318.. Test accuracy: 0.887\n",
      "Epoch 2/5.. Train loss: 0.704.. Test loss: 0.195.. Test accuracy: 0.953\n",
      "Epoch 2/5.. Train loss: 0.963.. Test loss: 0.267.. Test accuracy: 0.918\n",
      "Epoch 2/5.. Train loss: 0.909.. Test loss: 0.335.. Test accuracy: 0.902\n",
      "Epoch 2/5.. Train loss: 0.777.. Test loss: 0.264.. Test accuracy: 0.927\n",
      "Epoch 2/5.. Train loss: 0.981.. Test loss: 0.336.. Test accuracy: 0.909\n",
      "Epoch 2/5.. Train loss: 0.839.. Test loss: 0.467.. Test accuracy: 0.888\n",
      "Epoch 2/5.. Train loss: 1.038.. Test loss: 0.264.. Test accuracy: 0.933\n",
      "Epoch 2/5.. Train loss: 0.549.. Test loss: 0.223.. Test accuracy: 0.950\n",
      "Epoch 2/5.. Train loss: 0.871.. Test loss: 0.274.. Test accuracy: 0.929\n",
      "Epoch 2/5.. Train loss: 0.454.. Test loss: 0.231.. Test accuracy: 0.938\n",
      "Epoch 2/5.. Train loss: 0.798.. Test loss: 0.207.. Test accuracy: 0.946\n",
      "Epoch 2/5.. Train loss: 0.806.. Test loss: 0.150.. Test accuracy: 0.966\n",
      "Epoch 2/5.. Train loss: 0.461.. Test loss: 0.238.. Test accuracy: 0.935\n",
      "Epoch 2/5.. Train loss: 0.515.. Test loss: 0.233.. Test accuracy: 0.931\n",
      "Epoch 2/5.. Train loss: 0.547.. Test loss: 0.170.. Test accuracy: 0.949\n",
      "Epoch 2/5.. Train loss: 0.599.. Test loss: 0.238.. Test accuracy: 0.934\n",
      "Epoch 2/5.. Train loss: 1.077.. Test loss: 0.241.. Test accuracy: 0.932\n",
      "Epoch 2/5.. Train loss: 0.578.. Test loss: 0.431.. Test accuracy: 0.883\n",
      "Epoch 2/5.. Train loss: 0.797.. Test loss: 0.350.. Test accuracy: 0.914\n",
      "Epoch 2/5.. Train loss: 1.180.. Test loss: 0.261.. Test accuracy: 0.933\n",
      "Epoch 2/5.. Train loss: 0.443.. Test loss: 0.321.. Test accuracy: 0.918\n",
      "Epoch 2/5.. Train loss: 1.314.. Test loss: 0.251.. Test accuracy: 0.930\n",
      "Epoch 2/5.. Train loss: 0.704.. Test loss: 0.185.. Test accuracy: 0.952\n",
      "Epoch 2/5.. Train loss: 0.837.. Test loss: 0.212.. Test accuracy: 0.944\n",
      "Epoch 2/5.. Train loss: 0.677.. Test loss: 0.363.. Test accuracy: 0.903\n",
      "Epoch 2/5.. Train loss: 0.438.. Test loss: 0.177.. Test accuracy: 0.951\n",
      "Epoch 2/5.. Train loss: 0.483.. Test loss: 0.327.. Test accuracy: 0.911\n",
      "Epoch 2/5.. Train loss: 0.806.. Test loss: 0.214.. Test accuracy: 0.946\n",
      "Epoch 2/5.. Train loss: 0.589.. Test loss: 0.137.. Test accuracy: 0.963\n",
      "Epoch 2/5.. Train loss: 0.754.. Test loss: 0.230.. Test accuracy: 0.930\n",
      "Epoch 2/5.. Train loss: 0.770.. Test loss: 0.216.. Test accuracy: 0.929\n",
      "Epoch 2/5.. Train loss: 0.747.. Test loss: 0.319.. Test accuracy: 0.911\n",
      "Epoch 2/5.. Train loss: 0.773.. Test loss: 0.283.. Test accuracy: 0.932\n",
      "Epoch 2/5.. Train loss: 0.952.. Test loss: 0.164.. Test accuracy: 0.957\n",
      "Epoch 2/5.. Train loss: 0.851.. Test loss: 0.186.. Test accuracy: 0.947\n",
      "Epoch 2/5.. Train loss: 0.816.. Test loss: 0.332.. Test accuracy: 0.912\n",
      "Epoch 2/5.. Train loss: 1.051.. Test loss: 0.313.. Test accuracy: 0.908\n",
      "Epoch 3/5.. Train loss: 0.840.. Test loss: 0.371.. Test accuracy: 0.904\n",
      "Epoch 3/5.. Train loss: 0.847.. Test loss: 0.255.. Test accuracy: 0.934\n",
      "Epoch 3/5.. Train loss: 0.829.. Test loss: 0.304.. Test accuracy: 0.904\n",
      "Epoch 3/5.. Train loss: 0.877.. Test loss: 0.143.. Test accuracy: 0.960\n",
      "Epoch 3/5.. Train loss: 0.825.. Test loss: 0.188.. Test accuracy: 0.949\n",
      "Epoch 3/5.. Train loss: 0.766.. Test loss: 0.130.. Test accuracy: 0.961\n",
      "Epoch 3/5.. Train loss: 0.854.. Test loss: 0.162.. Test accuracy: 0.952\n",
      "Epoch 3/5.. Train loss: 1.044.. Test loss: 0.319.. Test accuracy: 0.916\n",
      "Epoch 3/5.. Train loss: 0.774.. Test loss: 0.239.. Test accuracy: 0.936\n",
      "Epoch 3/5.. Train loss: 0.733.. Test loss: 0.167.. Test accuracy: 0.956\n",
      "Epoch 3/5.. Train loss: 0.684.. Test loss: 0.157.. Test accuracy: 0.958\n",
      "Epoch 3/5.. Train loss: 0.746.. Test loss: 0.123.. Test accuracy: 0.969\n",
      "Epoch 3/5.. Train loss: 0.564.. Test loss: 0.226.. Test accuracy: 0.935\n",
      "Epoch 3/5.. Train loss: 0.515.. Test loss: 0.228.. Test accuracy: 0.932\n",
      "Epoch 3/5.. Train loss: 0.494.. Test loss: 0.164.. Test accuracy: 0.956\n",
      "Epoch 3/5.. Train loss: 0.751.. Test loss: 0.265.. Test accuracy: 0.925\n",
      "Epoch 3/5.. Train loss: 0.675.. Test loss: 0.171.. Test accuracy: 0.954\n",
      "Epoch 3/5.. Train loss: 0.956.. Test loss: 0.186.. Test accuracy: 0.951\n",
      "Epoch 3/5.. Train loss: 0.441.. Test loss: 0.536.. Test accuracy: 0.865\n",
      "Epoch 3/5.. Train loss: 0.666.. Test loss: 0.159.. Test accuracy: 0.961\n",
      "Epoch 3/5.. Train loss: 0.589.. Test loss: 0.208.. Test accuracy: 0.939\n",
      "Epoch 3/5.. Train loss: 0.592.. Test loss: 0.186.. Test accuracy: 0.944\n",
      "Epoch 3/5.. Train loss: 0.358.. Test loss: 0.167.. Test accuracy: 0.952\n",
      "Epoch 3/5.. Train loss: 0.482.. Test loss: 0.118.. Test accuracy: 0.968\n",
      "Epoch 3/5.. Train loss: 0.556.. Test loss: 0.158.. Test accuracy: 0.959\n",
      "Epoch 3/5.. Train loss: 0.134.. Test loss: 0.180.. Test accuracy: 0.950\n",
      "Epoch 3/5.. Train loss: 0.631.. Test loss: 0.134.. Test accuracy: 0.957\n",
      "Epoch 3/5.. Train loss: 0.510.. Test loss: 0.147.. Test accuracy: 0.953\n",
      "Epoch 3/5.. Train loss: 1.054.. Test loss: 0.099.. Test accuracy: 0.966\n",
      "Epoch 3/5.. Train loss: 0.469.. Test loss: 0.209.. Test accuracy: 0.947\n",
      "Epoch 3/5.. Train loss: 0.546.. Test loss: 0.153.. Test accuracy: 0.963\n",
      "Epoch 3/5.. Train loss: 0.287.. Test loss: 0.227.. Test accuracy: 0.942\n",
      "Epoch 3/5.. Train loss: 0.455.. Test loss: 0.177.. Test accuracy: 0.951\n",
      "Epoch 3/5.. Train loss: 0.644.. Test loss: 0.170.. Test accuracy: 0.951\n",
      "Epoch 3/5.. Train loss: 0.660.. Test loss: 0.156.. Test accuracy: 0.963\n",
      "Epoch 3/5.. Train loss: 0.955.. Test loss: 0.159.. Test accuracy: 0.962\n",
      "Epoch 3/5.. Train loss: 0.851.. Test loss: 0.168.. Test accuracy: 0.955\n",
      "Epoch 3/5.. Train loss: 0.377.. Test loss: 0.285.. Test accuracy: 0.923\n",
      "Epoch 3/5.. Train loss: 0.917.. Test loss: 0.250.. Test accuracy: 0.935\n",
      "Epoch 3/5.. Train loss: 0.514.. Test loss: 0.222.. Test accuracy: 0.939\n",
      "Epoch 3/5.. Train loss: 0.366.. Test loss: 0.202.. Test accuracy: 0.939\n",
      "Epoch 3/5.. Train loss: 1.011.. Test loss: 0.213.. Test accuracy: 0.935\n",
      "Epoch 3/5.. Train loss: 0.895.. Test loss: 0.502.. Test accuracy: 0.887\n",
      "Epoch 3/5.. Train loss: 0.846.. Test loss: 0.351.. Test accuracy: 0.918\n",
      "Epoch 3/5.. Train loss: 0.401.. Test loss: 0.200.. Test accuracy: 0.949\n",
      "Epoch 3/5.. Train loss: 0.621.. Test loss: 0.231.. Test accuracy: 0.940\n",
      "Epoch 3/5.. Train loss: 0.536.. Test loss: 0.442.. Test accuracy: 0.882\n",
      "Epoch 3/5.. Train loss: 0.724.. Test loss: 0.288.. Test accuracy: 0.915\n",
      "Epoch 3/5.. Train loss: 0.587.. Test loss: 0.155.. Test accuracy: 0.956\n",
      "Epoch 3/5.. Train loss: 0.593.. Test loss: 0.175.. Test accuracy: 0.951\n",
      "Epoch 4/5.. Train loss: 0.509.. Test loss: 0.152.. Test accuracy: 0.962\n",
      "Epoch 4/5.. Train loss: 0.296.. Test loss: 0.185.. Test accuracy: 0.953\n",
      "Epoch 4/5.. Train loss: 0.481.. Test loss: 0.221.. Test accuracy: 0.931\n",
      "Epoch 4/5.. Train loss: 0.401.. Test loss: 0.181.. Test accuracy: 0.954\n",
      "Epoch 4/5.. Train loss: 1.150.. Test loss: 0.143.. Test accuracy: 0.957\n",
      "Epoch 4/5.. Train loss: 0.987.. Test loss: 0.190.. Test accuracy: 0.947\n",
      "Epoch 4/5.. Train loss: 0.774.. Test loss: 0.268.. Test accuracy: 0.932\n",
      "Epoch 4/5.. Train loss: 0.416.. Test loss: 0.219.. Test accuracy: 0.946\n",
      "Epoch 4/5.. Train loss: 0.793.. Test loss: 0.177.. Test accuracy: 0.957\n",
      "Epoch 4/5.. Train loss: 0.692.. Test loss: 0.161.. Test accuracy: 0.961\n",
      "Epoch 4/5.. Train loss: 0.407.. Test loss: 0.189.. Test accuracy: 0.957\n",
      "Epoch 4/5.. Train loss: 0.504.. Test loss: 0.141.. Test accuracy: 0.963\n",
      "Epoch 4/5.. Train loss: 0.466.. Test loss: 0.142.. Test accuracy: 0.962\n",
      "Epoch 4/5.. Train loss: 0.781.. Test loss: 0.104.. Test accuracy: 0.972\n",
      "Epoch 4/5.. Train loss: 0.724.. Test loss: 0.151.. Test accuracy: 0.960\n",
      "Epoch 4/5.. Train loss: 0.599.. Test loss: 0.159.. Test accuracy: 0.960\n",
      "Epoch 4/5.. Train loss: 0.704.. Test loss: 0.191.. Test accuracy: 0.953\n",
      "Epoch 4/5.. Train loss: 0.350.. Test loss: 0.138.. Test accuracy: 0.962\n",
      "Epoch 4/5.. Train loss: 0.527.. Test loss: 0.121.. Test accuracy: 0.963\n",
      "Epoch 4/5.. Train loss: 0.584.. Test loss: 0.135.. Test accuracy: 0.959\n",
      "Epoch 4/5.. Train loss: 0.802.. Test loss: 0.108.. Test accuracy: 0.969\n",
      "Epoch 4/5.. Train loss: 0.689.. Test loss: 0.102.. Test accuracy: 0.971\n",
      "Epoch 4/5.. Train loss: 0.333.. Test loss: 0.148.. Test accuracy: 0.960\n",
      "Epoch 4/5.. Train loss: 0.644.. Test loss: 0.140.. Test accuracy: 0.962\n",
      "Epoch 4/5.. Train loss: 0.704.. Test loss: 0.123.. Test accuracy: 0.964\n",
      "Epoch 4/5.. Train loss: 0.468.. Test loss: 0.293.. Test accuracy: 0.925\n",
      "Epoch 4/5.. Train loss: 0.611.. Test loss: 0.221.. Test accuracy: 0.941\n",
      "Epoch 4/5.. Train loss: 0.811.. Test loss: 0.226.. Test accuracy: 0.938\n",
      "Epoch 4/5.. Train loss: 0.510.. Test loss: 0.216.. Test accuracy: 0.941\n",
      "Epoch 4/5.. Train loss: 0.705.. Test loss: 0.144.. Test accuracy: 0.956\n",
      "Epoch 4/5.. Train loss: 0.599.. Test loss: 0.110.. Test accuracy: 0.977\n",
      "Epoch 4/5.. Train loss: 0.420.. Test loss: 0.150.. Test accuracy: 0.956\n",
      "Epoch 4/5.. Train loss: 0.365.. Test loss: 0.147.. Test accuracy: 0.963\n",
      "Epoch 4/5.. Train loss: 0.506.. Test loss: 0.168.. Test accuracy: 0.955\n",
      "Epoch 4/5.. Train loss: 0.515.. Test loss: 0.141.. Test accuracy: 0.957\n",
      "Epoch 4/5.. Train loss: 1.049.. Test loss: 0.152.. Test accuracy: 0.957\n",
      "Epoch 4/5.. Train loss: 0.693.. Test loss: 0.243.. Test accuracy: 0.942\n",
      "Epoch 4/5.. Train loss: 1.108.. Test loss: 0.283.. Test accuracy: 0.931\n",
      "Epoch 4/5.. Train loss: 0.721.. Test loss: 0.232.. Test accuracy: 0.942\n",
      "Epoch 4/5.. Train loss: 0.360.. Test loss: 0.206.. Test accuracy: 0.937\n",
      "Epoch 4/5.. Train loss: 0.403.. Test loss: 0.186.. Test accuracy: 0.955\n",
      "Epoch 4/5.. Train loss: 0.549.. Test loss: 0.181.. Test accuracy: 0.953\n",
      "Epoch 4/5.. Train loss: 0.679.. Test loss: 0.154.. Test accuracy: 0.961\n",
      "Epoch 4/5.. Train loss: 0.713.. Test loss: 0.174.. Test accuracy: 0.952\n",
      "Epoch 4/5.. Train loss: 0.570.. Test loss: 0.244.. Test accuracy: 0.938\n",
      "Epoch 4/5.. Train loss: 0.557.. Test loss: 0.336.. Test accuracy: 0.918\n",
      "Epoch 4/5.. Train loss: 0.604.. Test loss: 0.148.. Test accuracy: 0.961\n",
      "Epoch 4/5.. Train loss: 0.412.. Test loss: 0.230.. Test accuracy: 0.929\n",
      "Epoch 4/5.. Train loss: 0.632.. Test loss: 0.153.. Test accuracy: 0.954\n",
      "Epoch 4/5.. Train loss: 0.375.. Test loss: 0.114.. Test accuracy: 0.969\n",
      "Epoch 5/5.. Train loss: 0.728.. Test loss: 0.158.. Test accuracy: 0.957\n",
      "Epoch 5/5.. Train loss: 0.481.. Test loss: 0.144.. Test accuracy: 0.961\n",
      "Epoch 5/5.. Train loss: 0.298.. Test loss: 0.197.. Test accuracy: 0.940\n",
      "Epoch 5/5.. Train loss: 0.592.. Test loss: 0.172.. Test accuracy: 0.957\n",
      "Epoch 5/5.. Train loss: 0.810.. Test loss: 0.164.. Test accuracy: 0.961\n",
      "Epoch 5/5.. Train loss: 0.873.. Test loss: 0.137.. Test accuracy: 0.961\n",
      "Epoch 5/5.. Train loss: 0.665.. Test loss: 0.113.. Test accuracy: 0.968\n",
      "Epoch 5/5.. Train loss: 0.698.. Test loss: 0.179.. Test accuracy: 0.960\n",
      "Epoch 5/5.. Train loss: 0.804.. Test loss: 0.441.. Test accuracy: 0.911\n",
      "Epoch 5/5.. Train loss: 0.528.. Test loss: 0.296.. Test accuracy: 0.916\n",
      "Epoch 5/5.. Train loss: 0.938.. Test loss: 0.125.. Test accuracy: 0.972\n",
      "Epoch 5/5.. Train loss: 0.674.. Test loss: 0.093.. Test accuracy: 0.977\n",
      "Epoch 5/5.. Train loss: 0.287.. Test loss: 0.158.. Test accuracy: 0.958\n",
      "Epoch 5/5.. Train loss: 0.990.. Test loss: 0.116.. Test accuracy: 0.968\n",
      "Epoch 5/5.. Train loss: 0.566.. Test loss: 0.123.. Test accuracy: 0.966\n",
      "Epoch 5/5.. Train loss: 0.563.. Test loss: 0.171.. Test accuracy: 0.960\n",
      "Epoch 5/5.. Train loss: 0.544.. Test loss: 0.144.. Test accuracy: 0.952\n",
      "Epoch 5/5.. Train loss: 0.410.. Test loss: 0.111.. Test accuracy: 0.970\n",
      "Epoch 5/5.. Train loss: 0.499.. Test loss: 0.141.. Test accuracy: 0.964\n",
      "Epoch 5/5.. Train loss: 0.562.. Test loss: 0.151.. Test accuracy: 0.967\n",
      "Epoch 5/5.. Train loss: 0.356.. Test loss: 0.218.. Test accuracy: 0.947\n",
      "Epoch 5/5.. Train loss: 0.422.. Test loss: 0.235.. Test accuracy: 0.943\n",
      "Epoch 5/5.. Train loss: 0.298.. Test loss: 0.098.. Test accuracy: 0.979\n",
      "Epoch 5/5.. Train loss: 0.433.. Test loss: 0.130.. Test accuracy: 0.964\n",
      "Epoch 5/5.. Train loss: 1.408.. Test loss: 0.161.. Test accuracy: 0.957\n",
      "Epoch 5/5.. Train loss: 0.570.. Test loss: 0.136.. Test accuracy: 0.966\n",
      "Epoch 5/5.. Train loss: 0.472.. Test loss: 0.124.. Test accuracy: 0.967\n",
      "Epoch 5/5.. Train loss: 0.184.. Test loss: 0.162.. Test accuracy: 0.966\n",
      "Epoch 5/5.. Train loss: 0.324.. Test loss: 0.142.. Test accuracy: 0.965\n",
      "Epoch 5/5.. Train loss: 0.573.. Test loss: 0.107.. Test accuracy: 0.971\n",
      "Epoch 5/5.. Train loss: 0.436.. Test loss: 0.153.. Test accuracy: 0.960\n",
      "Epoch 5/5.. Train loss: 0.535.. Test loss: 0.252.. Test accuracy: 0.940\n",
      "Epoch 5/5.. Train loss: 1.008.. Test loss: 0.156.. Test accuracy: 0.957\n",
      "Epoch 5/5.. Train loss: 0.480.. Test loss: 0.200.. Test accuracy: 0.948\n",
      "Epoch 5/5.. Train loss: 0.226.. Test loss: 0.236.. Test accuracy: 0.945\n",
      "Epoch 5/5.. Train loss: 0.545.. Test loss: 0.235.. Test accuracy: 0.935\n",
      "Epoch 5/5.. Train loss: 0.446.. Test loss: 0.157.. Test accuracy: 0.961\n",
      "Epoch 5/5.. Train loss: 0.310.. Test loss: 0.115.. Test accuracy: 0.971\n",
      "Epoch 5/5.. Train loss: 0.584.. Test loss: 0.164.. Test accuracy: 0.964\n",
      "Epoch 5/5.. Train loss: 0.659.. Test loss: 0.290.. Test accuracy: 0.935\n",
      "Epoch 5/5.. Train loss: 0.675.. Test loss: 0.142.. Test accuracy: 0.970\n",
      "Epoch 5/5.. Train loss: 0.568.. Test loss: 0.254.. Test accuracy: 0.939\n",
      "Epoch 5/5.. Train loss: 0.471.. Test loss: 0.296.. Test accuracy: 0.927\n",
      "Epoch 5/5.. Train loss: 0.605.. Test loss: 0.303.. Test accuracy: 0.919\n",
      "Epoch 5/5.. Train loss: 0.318.. Test loss: 0.166.. Test accuracy: 0.957\n",
      "Epoch 5/5.. Train loss: 0.999.. Test loss: 0.114.. Test accuracy: 0.972\n",
      "Epoch 5/5.. Train loss: 0.300.. Test loss: 0.103.. Test accuracy: 0.978\n",
      "Epoch 5/5.. Train loss: 0.345.. Test loss: 0.115.. Test accuracy: 0.973\n",
      "Epoch 5/5.. Train loss: 0.416.. Test loss: 0.122.. Test accuracy: 0.973\n",
      "Epoch 5/5.. Train loss: 0.392.. Test loss: 0.103.. Test accuracy: 0.976\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 10\n",
    "train_losses, test_losses = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for inputs, labels in trainloader:\n",
    "        steps += 1\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logps = model.forward(inputs)\n",
    "        loss = criterion(logps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in validloader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    logps = model.forward(inputs)\n",
    "                    batch_loss = criterion(logps, labels)\n",
    "                    test_loss += batch_loss.item()\n",
    "                    \n",
    "                    ps = torch.exp(logps)\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "\n",
    "            train_losses.append(running_loss/len(trainloader))\n",
    "            test_losses.append(test_loss/len(validloader))                    \n",
    "            print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
    "                  f\"Test loss: {test_loss/len(validloader):.3f}.. \"\n",
    "                  f\"Test accuracy: {accuracy/len(validloader):.3f}\")\n",
    "            running_loss = 0\n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "XC3Kyoe2qk_J",
    "outputId": "fb336484-8c0d-444b-9d71-743701e8e1ca"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nk1IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(test_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Trabalho_deep_colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
