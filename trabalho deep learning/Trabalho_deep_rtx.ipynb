{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5QEyByP8f0oo"
   },
   "outputs": [],
   "source": [
    "#!unzip leapGestRecog.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZOw5sMMIoENr"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "BATCH_SIZE = 64\n",
    "RESIZE = 32\n",
    "EPOCHS = 10\n",
    "MODEL = models.resnet50\n",
    "OUR_TOPOLOGY = nn.Sequential(nn.Linear(2048, 512),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(0.2),\n",
    "                                 nn.Linear(512, 10),\n",
    "                                 nn.LogSoftmax(dim=1))\n",
    "OPTIMIZER = optim.Adam\n",
    "OPTIMIZER_PARAMETERS = {\"lr\": 0.003}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Resize(RESIZE),\n",
    "                                transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "alldataset = torchvision.datasets.ImageFolder(root='./leapGestRecog/00', transform=transform)\n",
    "\n",
    "for i in range(1, 10):\n",
    "    folder = torchvision.datasets.ImageFolder(root='./leapGestRecog/0{}'.format(i), transform=transform)\n",
    "    alldataset = torch.utils.data.ConcatDataset([alldataset, folder])\n",
    "    \n",
    "num_train = len(alldataset)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(0.1 * num_train))\n",
    "\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_idx, test_idx = indices[split:], indices[:split]\n",
    "train_idx, valid_idx = train_idx[split:], train_idx[:split]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    alldataset, batch_size=BATCH_SIZE, sampler=train_sampler,\n",
    "    num_workers=12\n",
    ")\n",
    "validloader = torch.utils.data.DataLoader(\n",
    "    alldataset, batch_size=BATCH_SIZE, sampler=valid_sampler,\n",
    "    num_workers=12\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    alldataset, batch_size=BATCH_SIZE, sampler=test_sampler,\n",
    "    num_workers=12\n",
    ")\n",
    "\n",
    "classes = ('01_palm', '02_l', '03_fist', '04_fist_moved',\n",
    "           '05_thumb', '06_index', '07_ok', '08_palm_moved', '09_c', '10_down')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 32 32\n"
     ]
    }
   ],
   "source": [
    "print(len(trainloader), len(validloader), len(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "n90JSpuloYuR",
    "outputId": "23eb49a9-2a81-4e15-fd8e-b4eca789a3b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01_palm 03_fist  02_l 08_palm_moved  09_c  02_l 06_index 07_ok  02_l 06_index  02_l 10_down 03_fist 04_fist_moved 03_fist 05_thumb 05_thumb 04_fist_moved  09_c 10_down 03_fist  02_l 08_palm_moved 04_fist_moved 07_ok 04_fist_moved  02_l  09_c 06_index  02_l 04_fist_moved  02_l 05_thumb 03_fist 07_ok  02_l  09_c 08_palm_moved 08_palm_moved  09_c 10_down 05_thumb 08_palm_moved 03_fist 08_palm_moved 05_thumb 05_thumb 07_ok 05_thumb 01_palm  09_c  09_c 04_fist_moved 10_down 04_fist_moved  02_l 08_palm_moved 10_down  02_l 08_palm_moved 07_ok 05_thumb  02_l  02_l\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(BATCH_SIZE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "glWomJ_GsumD",
    "outputId": "c1fee796-c081-49e0-b416-2a53e06b89ed"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Vb6p-RXwqW2X",
    "outputId": "e89107f5-b262-4c90-82a3-a654c286b074"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = MODEL(pretrained=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "DMLQdHBvqYMp",
    "outputId": "ee75cc7b-f7f9-4276-cee1-a3953cd1cf35"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=10, bias=True)\n",
       "    (4): LogSoftmax()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Freeze parameters so we don't backprop through them\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "model.fc = OUR_TOPOLOGY\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = OPTIMIZER(model.parameters(), **OPTIMIZER_PARAMETERS)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Ka-Lc5hIqceN",
    "outputId": "82ce33f3-ca21-4ab0-b5c0-a527e67fe4bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10.. Train loss: 2.665.. Test loss: 2.116.. Test accuracy: 0.244\n",
      "Epoch 1/10.. Train loss: 1.284.. Test loss: 1.773.. Test accuracy: 0.393\n",
      "Epoch 1/10.. Train loss: 0.940.. Test loss: 1.539.. Test accuracy: 0.495\n",
      "Epoch 1/10.. Train loss: 0.736.. Test loss: 1.732.. Test accuracy: 0.457\n",
      "Epoch 1/10.. Train loss: 0.600.. Test loss: 1.872.. Test accuracy: 0.467\n",
      "Epoch 1/10.. Train loss: 0.565.. Test loss: 1.849.. Test accuracy: 0.472\n",
      "Epoch 1/10.. Train loss: 0.535.. Test loss: 1.498.. Test accuracy: 0.606\n",
      "Epoch 1/10.. Train loss: 0.443.. Test loss: 0.772.. Test accuracy: 0.799\n",
      "Epoch 1/10.. Train loss: 0.408.. Test loss: 0.299.. Test accuracy: 0.912\n",
      "Epoch 1/10.. Train loss: 0.379.. Test loss: 0.293.. Test accuracy: 0.908\n",
      "Epoch 1/10.. Train loss: 0.366.. Test loss: 0.249.. Test accuracy: 0.930\n",
      "Epoch 1/10.. Train loss: 0.337.. Test loss: 0.211.. Test accuracy: 0.942\n",
      "Epoch 1/10.. Train loss: 0.333.. Test loss: 0.154.. Test accuracy: 0.965\n",
      "Epoch 1/10.. Train loss: 0.315.. Test loss: 0.147.. Test accuracy: 0.965\n",
      "Epoch 1/10.. Train loss: 0.275.. Test loss: 0.175.. Test accuracy: 0.950\n",
      "Epoch 1/10.. Train loss: 0.360.. Test loss: 0.166.. Test accuracy: 0.955\n",
      "Epoch 1/10.. Train loss: 0.189.. Test loss: 0.165.. Test accuracy: 0.953\n",
      "Epoch 1/10.. Train loss: 0.222.. Test loss: 0.175.. Test accuracy: 0.951\n",
      "Epoch 1/10.. Train loss: 0.263.. Test loss: 0.127.. Test accuracy: 0.967\n",
      "Epoch 1/10.. Train loss: 0.237.. Test loss: 0.107.. Test accuracy: 0.969\n",
      "Epoch 1/10.. Train loss: 0.222.. Test loss: 0.094.. Test accuracy: 0.976\n",
      "Epoch 1/10.. Train loss: 0.201.. Test loss: 0.150.. Test accuracy: 0.955\n",
      "Epoch 1/10.. Train loss: 0.258.. Test loss: 0.099.. Test accuracy: 0.972\n",
      "Epoch 1/10.. Train loss: 0.193.. Test loss: 0.093.. Test accuracy: 0.978\n",
      "Epoch 1/10.. Train loss: 0.224.. Test loss: 0.115.. Test accuracy: 0.970\n",
      "Epoch 2/10.. Train loss: 0.214.. Test loss: 0.097.. Test accuracy: 0.972\n",
      "Epoch 2/10.. Train loss: 0.212.. Test loss: 0.118.. Test accuracy: 0.965\n",
      "Epoch 2/10.. Train loss: 0.178.. Test loss: 0.098.. Test accuracy: 0.969\n",
      "Epoch 2/10.. Train loss: 0.129.. Test loss: 0.072.. Test accuracy: 0.981\n",
      "Epoch 2/10.. Train loss: 0.130.. Test loss: 0.083.. Test accuracy: 0.980\n",
      "Epoch 2/10.. Train loss: 0.102.. Test loss: 0.061.. Test accuracy: 0.983\n",
      "Epoch 2/10.. Train loss: 0.103.. Test loss: 0.065.. Test accuracy: 0.986\n",
      "Epoch 2/10.. Train loss: 0.087.. Test loss: 0.065.. Test accuracy: 0.984\n",
      "Epoch 2/10.. Train loss: 0.151.. Test loss: 0.089.. Test accuracy: 0.974\n",
      "Epoch 2/10.. Train loss: 0.106.. Test loss: 0.065.. Test accuracy: 0.982\n",
      "Epoch 2/10.. Train loss: 0.104.. Test loss: 0.083.. Test accuracy: 0.979\n",
      "Epoch 2/10.. Train loss: 0.120.. Test loss: 0.100.. Test accuracy: 0.971\n",
      "Epoch 2/10.. Train loss: 0.122.. Test loss: 0.058.. Test accuracy: 0.984\n",
      "Epoch 2/10.. Train loss: 0.079.. Test loss: 0.073.. Test accuracy: 0.976\n",
      "Epoch 2/10.. Train loss: 0.174.. Test loss: 0.087.. Test accuracy: 0.976\n",
      "Epoch 2/10.. Train loss: 0.090.. Test loss: 0.051.. Test accuracy: 0.985\n",
      "Epoch 2/10.. Train loss: 0.134.. Test loss: 0.048.. Test accuracy: 0.990\n",
      "Epoch 2/10.. Train loss: 0.121.. Test loss: 0.059.. Test accuracy: 0.984\n",
      "Epoch 2/10.. Train loss: 0.148.. Test loss: 0.121.. Test accuracy: 0.963\n",
      "Epoch 2/10.. Train loss: 0.176.. Test loss: 0.088.. Test accuracy: 0.976\n",
      "Epoch 2/10.. Train loss: 0.186.. Test loss: 0.074.. Test accuracy: 0.980\n",
      "Epoch 2/10.. Train loss: 0.132.. Test loss: 0.088.. Test accuracy: 0.974\n",
      "Epoch 2/10.. Train loss: 0.140.. Test loss: 0.070.. Test accuracy: 0.983\n",
      "Epoch 2/10.. Train loss: 0.095.. Test loss: 0.052.. Test accuracy: 0.984\n",
      "Epoch 2/10.. Train loss: 0.134.. Test loss: 0.056.. Test accuracy: 0.986\n",
      "Epoch 3/10.. Train loss: 0.135.. Test loss: 0.072.. Test accuracy: 0.978\n",
      "Epoch 3/10.. Train loss: 0.110.. Test loss: 0.061.. Test accuracy: 0.983\n",
      "Epoch 3/10.. Train loss: 0.150.. Test loss: 0.038.. Test accuracy: 0.989\n",
      "Epoch 3/10.. Train loss: 0.086.. Test loss: 0.050.. Test accuracy: 0.986\n",
      "Epoch 3/10.. Train loss: 0.099.. Test loss: 0.063.. Test accuracy: 0.982\n",
      "Epoch 3/10.. Train loss: 0.125.. Test loss: 0.056.. Test accuracy: 0.984\n",
      "Epoch 3/10.. Train loss: 0.105.. Test loss: 0.037.. Test accuracy: 0.989\n",
      "Epoch 3/10.. Train loss: 0.115.. Test loss: 0.043.. Test accuracy: 0.987\n",
      "Epoch 3/10.. Train loss: 0.112.. Test loss: 0.046.. Test accuracy: 0.990\n",
      "Epoch 3/10.. Train loss: 0.104.. Test loss: 0.037.. Test accuracy: 0.992\n",
      "Epoch 3/10.. Train loss: 0.121.. Test loss: 0.057.. Test accuracy: 0.981\n",
      "Epoch 3/10.. Train loss: 0.115.. Test loss: 0.071.. Test accuracy: 0.978\n",
      "Epoch 3/10.. Train loss: 0.131.. Test loss: 0.060.. Test accuracy: 0.983\n",
      "Epoch 3/10.. Train loss: 0.102.. Test loss: 0.056.. Test accuracy: 0.984\n",
      "Epoch 3/10.. Train loss: 0.097.. Test loss: 0.046.. Test accuracy: 0.987\n",
      "Epoch 3/10.. Train loss: 0.081.. Test loss: 0.036.. Test accuracy: 0.990\n",
      "Epoch 3/10.. Train loss: 0.078.. Test loss: 0.042.. Test accuracy: 0.988\n",
      "Epoch 3/10.. Train loss: 0.139.. Test loss: 0.044.. Test accuracy: 0.985\n",
      "Epoch 3/10.. Train loss: 0.078.. Test loss: 0.044.. Test accuracy: 0.986\n",
      "Epoch 3/10.. Train loss: 0.084.. Test loss: 0.084.. Test accuracy: 0.974\n",
      "Epoch 3/10.. Train loss: 0.131.. Test loss: 0.053.. Test accuracy: 0.984\n",
      "Epoch 3/10.. Train loss: 0.082.. Test loss: 0.064.. Test accuracy: 0.985\n",
      "Epoch 3/10.. Train loss: 0.140.. Test loss: 0.034.. Test accuracy: 0.988\n",
      "Epoch 3/10.. Train loss: 0.124.. Test loss: 0.048.. Test accuracy: 0.990\n",
      "Epoch 3/10.. Train loss: 0.107.. Test loss: 0.037.. Test accuracy: 0.991\n",
      "Epoch 4/10.. Train loss: 0.107.. Test loss: 0.044.. Test accuracy: 0.989\n",
      "Epoch 4/10.. Train loss: 0.094.. Test loss: 0.055.. Test accuracy: 0.985\n",
      "Epoch 4/10.. Train loss: 0.116.. Test loss: 0.045.. Test accuracy: 0.988\n",
      "Epoch 4/10.. Train loss: 0.078.. Test loss: 0.033.. Test accuracy: 0.990\n",
      "Epoch 4/10.. Train loss: 0.071.. Test loss: 0.046.. Test accuracy: 0.988\n",
      "Epoch 4/10.. Train loss: 0.077.. Test loss: 0.034.. Test accuracy: 0.991\n",
      "Epoch 4/10.. Train loss: 0.100.. Test loss: 0.029.. Test accuracy: 0.992\n",
      "Epoch 4/10.. Train loss: 0.046.. Test loss: 0.030.. Test accuracy: 0.992\n",
      "Epoch 4/10.. Train loss: 0.067.. Test loss: 0.049.. Test accuracy: 0.989\n",
      "Epoch 4/10.. Train loss: 0.099.. Test loss: 0.041.. Test accuracy: 0.987\n",
      "Epoch 4/10.. Train loss: 0.088.. Test loss: 0.036.. Test accuracy: 0.991\n",
      "Epoch 4/10.. Train loss: 0.078.. Test loss: 0.035.. Test accuracy: 0.990\n",
      "Epoch 4/10.. Train loss: 0.063.. Test loss: 0.065.. Test accuracy: 0.983\n",
      "Epoch 4/10.. Train loss: 0.124.. Test loss: 0.069.. Test accuracy: 0.981\n",
      "Epoch 4/10.. Train loss: 0.101.. Test loss: 0.041.. Test accuracy: 0.989\n",
      "Epoch 4/10.. Train loss: 0.090.. Test loss: 0.040.. Test accuracy: 0.988\n",
      "Epoch 4/10.. Train loss: 0.091.. Test loss: 0.041.. Test accuracy: 0.990\n",
      "Epoch 4/10.. Train loss: 0.087.. Test loss: 0.057.. Test accuracy: 0.984\n",
      "Epoch 4/10.. Train loss: 0.122.. Test loss: 0.052.. Test accuracy: 0.985\n",
      "Epoch 4/10.. Train loss: 0.107.. Test loss: 0.049.. Test accuracy: 0.988\n",
      "Epoch 4/10.. Train loss: 0.101.. Test loss: 0.038.. Test accuracy: 0.991\n",
      "Epoch 4/10.. Train loss: 0.065.. Test loss: 0.051.. Test accuracy: 0.985\n",
      "Epoch 4/10.. Train loss: 0.074.. Test loss: 0.049.. Test accuracy: 0.987\n",
      "Epoch 4/10.. Train loss: 0.056.. Test loss: 0.041.. Test accuracy: 0.989\n",
      "Epoch 4/10.. Train loss: 0.103.. Test loss: 0.034.. Test accuracy: 0.989\n",
      "Epoch 5/10.. Train loss: 0.049.. Test loss: 0.039.. Test accuracy: 0.988\n",
      "Epoch 5/10.. Train loss: 0.085.. Test loss: 0.040.. Test accuracy: 0.990\n",
      "Epoch 5/10.. Train loss: 0.091.. Test loss: 0.039.. Test accuracy: 0.991\n",
      "Epoch 5/10.. Train loss: 0.087.. Test loss: 0.031.. Test accuracy: 0.991\n",
      "Epoch 5/10.. Train loss: 0.096.. Test loss: 0.032.. Test accuracy: 0.990\n",
      "Epoch 5/10.. Train loss: 0.044.. Test loss: 0.040.. Test accuracy: 0.989\n",
      "Epoch 5/10.. Train loss: 0.055.. Test loss: 0.050.. Test accuracy: 0.989\n",
      "Epoch 5/10.. Train loss: 0.127.. Test loss: 0.068.. Test accuracy: 0.979\n",
      "Epoch 5/10.. Train loss: 0.068.. Test loss: 0.056.. Test accuracy: 0.988\n",
      "Epoch 5/10.. Train loss: 0.095.. Test loss: 0.050.. Test accuracy: 0.986\n",
      "Epoch 5/10.. Train loss: 0.066.. Test loss: 0.048.. Test accuracy: 0.986\n",
      "Epoch 5/10.. Train loss: 0.089.. Test loss: 0.051.. Test accuracy: 0.987\n",
      "Epoch 5/10.. Train loss: 0.116.. Test loss: 0.053.. Test accuracy: 0.984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10.. Train loss: 0.096.. Test loss: 0.034.. Test accuracy: 0.992\n",
      "Epoch 5/10.. Train loss: 0.080.. Test loss: 0.032.. Test accuracy: 0.992\n",
      "Epoch 5/10.. Train loss: 0.044.. Test loss: 0.032.. Test accuracy: 0.992\n",
      "Epoch 5/10.. Train loss: 0.080.. Test loss: 0.045.. Test accuracy: 0.988\n",
      "Epoch 5/10.. Train loss: 0.112.. Test loss: 0.042.. Test accuracy: 0.990\n",
      "Epoch 5/10.. Train loss: 0.113.. Test loss: 0.046.. Test accuracy: 0.988\n",
      "Epoch 5/10.. Train loss: 0.098.. Test loss: 0.056.. Test accuracy: 0.987\n",
      "Epoch 5/10.. Train loss: 0.071.. Test loss: 0.034.. Test accuracy: 0.991\n",
      "Epoch 5/10.. Train loss: 0.039.. Test loss: 0.041.. Test accuracy: 0.990\n",
      "Epoch 5/10.. Train loss: 0.054.. Test loss: 0.049.. Test accuracy: 0.989\n",
      "Epoch 5/10.. Train loss: 0.087.. Test loss: 0.039.. Test accuracy: 0.991\n",
      "Epoch 5/10.. Train loss: 0.072.. Test loss: 0.031.. Test accuracy: 0.993\n",
      "Epoch 6/10.. Train loss: 0.037.. Test loss: 0.042.. Test accuracy: 0.988\n",
      "Epoch 6/10.. Train loss: 0.058.. Test loss: 0.033.. Test accuracy: 0.992\n",
      "Epoch 6/10.. Train loss: 0.029.. Test loss: 0.028.. Test accuracy: 0.992\n",
      "Epoch 6/10.. Train loss: 0.044.. Test loss: 0.034.. Test accuracy: 0.990\n",
      "Epoch 6/10.. Train loss: 0.082.. Test loss: 0.032.. Test accuracy: 0.993\n",
      "Epoch 6/10.. Train loss: 0.069.. Test loss: 0.047.. Test accuracy: 0.988\n",
      "Epoch 6/10.. Train loss: 0.041.. Test loss: 0.035.. Test accuracy: 0.992\n",
      "Epoch 6/10.. Train loss: 0.064.. Test loss: 0.033.. Test accuracy: 0.993\n",
      "Epoch 6/10.. Train loss: 0.047.. Test loss: 0.034.. Test accuracy: 0.991\n",
      "Epoch 6/10.. Train loss: 0.022.. Test loss: 0.037.. Test accuracy: 0.992\n",
      "Epoch 6/10.. Train loss: 0.029.. Test loss: 0.040.. Test accuracy: 0.993\n",
      "Epoch 6/10.. Train loss: 0.057.. Test loss: 0.043.. Test accuracy: 0.989\n",
      "Epoch 6/10.. Train loss: 0.073.. Test loss: 0.042.. Test accuracy: 0.987\n",
      "Epoch 6/10.. Train loss: 0.051.. Test loss: 0.032.. Test accuracy: 0.993\n",
      "Epoch 6/10.. Train loss: 0.080.. Test loss: 0.028.. Test accuracy: 0.994\n",
      "Epoch 6/10.. Train loss: 0.062.. Test loss: 0.028.. Test accuracy: 0.994\n",
      "Epoch 6/10.. Train loss: 0.058.. Test loss: 0.045.. Test accuracy: 0.991\n",
      "Epoch 6/10.. Train loss: 0.077.. Test loss: 0.033.. Test accuracy: 0.988\n",
      "Epoch 6/10.. Train loss: 0.090.. Test loss: 0.030.. Test accuracy: 0.993\n",
      "Epoch 6/10.. Train loss: 0.129.. Test loss: 0.056.. Test accuracy: 0.986\n",
      "Epoch 6/10.. Train loss: 0.050.. Test loss: 0.034.. Test accuracy: 0.990\n",
      "Epoch 6/10.. Train loss: 0.088.. Test loss: 0.031.. Test accuracy: 0.993\n",
      "Epoch 6/10.. Train loss: 0.117.. Test loss: 0.046.. Test accuracy: 0.990\n",
      "Epoch 6/10.. Train loss: 0.081.. Test loss: 0.046.. Test accuracy: 0.990\n",
      "Epoch 6/10.. Train loss: 0.110.. Test loss: 0.038.. Test accuracy: 0.990\n",
      "Epoch 7/10.. Train loss: 0.091.. Test loss: 0.032.. Test accuracy: 0.994\n",
      "Epoch 7/10.. Train loss: 0.069.. Test loss: 0.034.. Test accuracy: 0.991\n",
      "Epoch 7/10.. Train loss: 0.056.. Test loss: 0.037.. Test accuracy: 0.990\n",
      "Epoch 7/10.. Train loss: 0.082.. Test loss: 0.049.. Test accuracy: 0.990\n",
      "Epoch 7/10.. Train loss: 0.057.. Test loss: 0.054.. Test accuracy: 0.989\n",
      "Epoch 7/10.. Train loss: 0.051.. Test loss: 0.053.. Test accuracy: 0.983\n",
      "Epoch 7/10.. Train loss: 0.049.. Test loss: 0.036.. Test accuracy: 0.994\n",
      "Epoch 7/10.. Train loss: 0.078.. Test loss: 0.030.. Test accuracy: 0.992\n",
      "Epoch 7/10.. Train loss: 0.055.. Test loss: 0.056.. Test accuracy: 0.987\n",
      "Epoch 7/10.. Train loss: 0.074.. Test loss: 0.055.. Test accuracy: 0.989\n",
      "Epoch 7/10.. Train loss: 0.073.. Test loss: 0.032.. Test accuracy: 0.994\n",
      "Epoch 7/10.. Train loss: 0.065.. Test loss: 0.038.. Test accuracy: 0.988\n",
      "Epoch 7/10.. Train loss: 0.078.. Test loss: 0.044.. Test accuracy: 0.989\n",
      "Epoch 7/10.. Train loss: 0.091.. Test loss: 0.039.. Test accuracy: 0.990\n",
      "Epoch 7/10.. Train loss: 0.070.. Test loss: 0.036.. Test accuracy: 0.990\n",
      "Epoch 7/10.. Train loss: 0.095.. Test loss: 0.038.. Test accuracy: 0.991\n",
      "Epoch 7/10.. Train loss: 0.054.. Test loss: 0.039.. Test accuracy: 0.990\n",
      "Epoch 7/10.. Train loss: 0.050.. Test loss: 0.028.. Test accuracy: 0.994\n",
      "Epoch 7/10.. Train loss: 0.082.. Test loss: 0.031.. Test accuracy: 0.994\n",
      "Epoch 7/10.. Train loss: 0.063.. Test loss: 0.029.. Test accuracy: 0.993\n",
      "Epoch 7/10.. Train loss: 0.056.. Test loss: 0.028.. Test accuracy: 0.995\n",
      "Epoch 7/10.. Train loss: 0.036.. Test loss: 0.028.. Test accuracy: 0.995\n",
      "Epoch 7/10.. Train loss: 0.078.. Test loss: 0.033.. Test accuracy: 0.993\n",
      "Epoch 7/10.. Train loss: 0.104.. Test loss: 0.096.. Test accuracy: 0.979\n",
      "Epoch 7/10.. Train loss: 0.165.. Test loss: 0.034.. Test accuracy: 0.992\n",
      "Epoch 8/10.. Train loss: 0.081.. Test loss: 0.032.. Test accuracy: 0.993\n",
      "Epoch 8/10.. Train loss: 0.067.. Test loss: 0.042.. Test accuracy: 0.991\n",
      "Epoch 8/10.. Train loss: 0.022.. Test loss: 0.023.. Test accuracy: 0.994\n",
      "Epoch 8/10.. Train loss: 0.056.. Test loss: 0.025.. Test accuracy: 0.994\n",
      "Epoch 8/10.. Train loss: 0.044.. Test loss: 0.028.. Test accuracy: 0.995\n",
      "Epoch 8/10.. Train loss: 0.054.. Test loss: 0.032.. Test accuracy: 0.994\n",
      "Epoch 8/10.. Train loss: 0.043.. Test loss: 0.032.. Test accuracy: 0.991\n",
      "Epoch 8/10.. Train loss: 0.065.. Test loss: 0.038.. Test accuracy: 0.995\n",
      "Epoch 8/10.. Train loss: 0.057.. Test loss: 0.023.. Test accuracy: 0.995\n",
      "Epoch 8/10.. Train loss: 0.055.. Test loss: 0.025.. Test accuracy: 0.996\n",
      "Epoch 8/10.. Train loss: 0.058.. Test loss: 0.036.. Test accuracy: 0.992\n",
      "Epoch 8/10.. Train loss: 0.063.. Test loss: 0.041.. Test accuracy: 0.993\n",
      "Epoch 8/10.. Train loss: 0.049.. Test loss: 0.031.. Test accuracy: 0.991\n",
      "Epoch 8/10.. Train loss: 0.059.. Test loss: 0.028.. Test accuracy: 0.994\n",
      "Epoch 8/10.. Train loss: 0.036.. Test loss: 0.030.. Test accuracy: 0.994\n",
      "Epoch 8/10.. Train loss: 0.039.. Test loss: 0.031.. Test accuracy: 0.994\n",
      "Epoch 8/10.. Train loss: 0.067.. Test loss: 0.033.. Test accuracy: 0.995\n",
      "Epoch 8/10.. Train loss: 0.047.. Test loss: 0.029.. Test accuracy: 0.993\n",
      "Epoch 8/10.. Train loss: 0.048.. Test loss: 0.045.. Test accuracy: 0.989\n",
      "Epoch 8/10.. Train loss: 0.112.. Test loss: 0.056.. Test accuracy: 0.987\n",
      "Epoch 8/10.. Train loss: 0.093.. Test loss: 0.053.. Test accuracy: 0.989\n",
      "Epoch 8/10.. Train loss: 0.097.. Test loss: 0.036.. Test accuracy: 0.993\n",
      "Epoch 8/10.. Train loss: 0.127.. Test loss: 0.022.. Test accuracy: 0.996\n",
      "Epoch 8/10.. Train loss: 0.101.. Test loss: 0.026.. Test accuracy: 0.994\n",
      "Epoch 8/10.. Train loss: 0.111.. Test loss: 0.026.. Test accuracy: 0.994\n",
      "Epoch 9/10.. Train loss: 0.138.. Test loss: 0.023.. Test accuracy: 0.995\n",
      "Epoch 9/10.. Train loss: 0.062.. Test loss: 0.077.. Test accuracy: 0.982\n",
      "Epoch 9/10.. Train loss: 0.097.. Test loss: 0.042.. Test accuracy: 0.991\n",
      "Epoch 9/10.. Train loss: 0.096.. Test loss: 0.031.. Test accuracy: 0.993\n",
      "Epoch 9/10.. Train loss: 0.053.. Test loss: 0.033.. Test accuracy: 0.993\n",
      "Epoch 9/10.. Train loss: 0.053.. Test loss: 0.031.. Test accuracy: 0.994\n",
      "Epoch 9/10.. Train loss: 0.049.. Test loss: 0.033.. Test accuracy: 0.992\n",
      "Epoch 9/10.. Train loss: 0.063.. Test loss: 0.037.. Test accuracy: 0.994\n",
      "Epoch 9/10.. Train loss: 0.041.. Test loss: 0.033.. Test accuracy: 0.993\n",
      "Epoch 9/10.. Train loss: 0.040.. Test loss: 0.030.. Test accuracy: 0.994\n",
      "Epoch 9/10.. Train loss: 0.083.. Test loss: 0.040.. Test accuracy: 0.992\n",
      "Epoch 9/10.. Train loss: 0.113.. Test loss: 0.038.. Test accuracy: 0.993\n",
      "Epoch 9/10.. Train loss: 0.038.. Test loss: 0.052.. Test accuracy: 0.989\n",
      "Epoch 9/10.. Train loss: 0.081.. Test loss: 0.036.. Test accuracy: 0.992\n",
      "Epoch 9/10.. Train loss: 0.062.. Test loss: 0.025.. Test accuracy: 0.996\n",
      "Epoch 9/10.. Train loss: 0.045.. Test loss: 0.033.. Test accuracy: 0.993\n",
      "Epoch 9/10.. Train loss: 0.086.. Test loss: 0.039.. Test accuracy: 0.989\n",
      "Epoch 9/10.. Train loss: 0.072.. Test loss: 0.030.. Test accuracy: 0.992\n",
      "Epoch 9/10.. Train loss: 0.051.. Test loss: 0.027.. Test accuracy: 0.994\n",
      "Epoch 9/10.. Train loss: 0.061.. Test loss: 0.045.. Test accuracy: 0.991\n",
      "Epoch 9/10.. Train loss: 0.080.. Test loss: 0.080.. Test accuracy: 0.992\n",
      "Epoch 9/10.. Train loss: 0.082.. Test loss: 0.048.. Test accuracy: 0.991\n",
      "Epoch 9/10.. Train loss: 0.099.. Test loss: 0.036.. Test accuracy: 0.993\n",
      "Epoch 9/10.. Train loss: 0.107.. Test loss: 0.035.. Test accuracy: 0.991\n",
      "Epoch 9/10.. Train loss: 0.089.. Test loss: 0.025.. Test accuracy: 0.995\n",
      "Epoch 10/10.. Train loss: 0.074.. Test loss: 0.038.. Test accuracy: 0.994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10.. Train loss: 0.083.. Test loss: 0.030.. Test accuracy: 0.994\n",
      "Epoch 10/10.. Train loss: 0.061.. Test loss: 0.033.. Test accuracy: 0.995\n",
      "Epoch 10/10.. Train loss: 0.085.. Test loss: 0.034.. Test accuracy: 0.993\n",
      "Epoch 10/10.. Train loss: 0.068.. Test loss: 0.036.. Test accuracy: 0.993\n",
      "Epoch 10/10.. Train loss: 0.058.. Test loss: 0.030.. Test accuracy: 0.992\n",
      "Epoch 10/10.. Train loss: 0.020.. Test loss: 0.032.. Test accuracy: 0.995\n",
      "Epoch 10/10.. Train loss: 0.039.. Test loss: 0.031.. Test accuracy: 0.995\n",
      "Epoch 10/10.. Train loss: 0.053.. Test loss: 0.042.. Test accuracy: 0.992\n",
      "Epoch 10/10.. Train loss: 0.028.. Test loss: 0.033.. Test accuracy: 0.990\n",
      "Epoch 10/10.. Train loss: 0.067.. Test loss: 0.042.. Test accuracy: 0.993\n",
      "Epoch 10/10.. Train loss: 0.061.. Test loss: 0.040.. Test accuracy: 0.993\n",
      "Epoch 10/10.. Train loss: 0.074.. Test loss: 0.034.. Test accuracy: 0.994\n",
      "Epoch 10/10.. Train loss: 0.072.. Test loss: 0.029.. Test accuracy: 0.995\n",
      "Epoch 10/10.. Train loss: 0.055.. Test loss: 0.026.. Test accuracy: 0.994\n",
      "Epoch 10/10.. Train loss: 0.059.. Test loss: 0.023.. Test accuracy: 0.995\n",
      "Epoch 10/10.. Train loss: 0.078.. Test loss: 0.018.. Test accuracy: 0.994\n",
      "Epoch 10/10.. Train loss: 0.040.. Test loss: 0.023.. Test accuracy: 0.995\n",
      "Epoch 10/10.. Train loss: 0.039.. Test loss: 0.028.. Test accuracy: 0.994\n",
      "Epoch 10/10.. Train loss: 0.062.. Test loss: 0.025.. Test accuracy: 0.994\n",
      "Epoch 10/10.. Train loss: 0.104.. Test loss: 0.038.. Test accuracy: 0.991\n",
      "Epoch 10/10.. Train loss: 0.082.. Test loss: 0.040.. Test accuracy: 0.992\n",
      "Epoch 10/10.. Train loss: 0.075.. Test loss: 0.031.. Test accuracy: 0.993\n",
      "Epoch 10/10.. Train loss: 0.069.. Test loss: 0.029.. Test accuracy: 0.992\n",
      "Epoch 10/10.. Train loss: 0.064.. Test loss: 0.027.. Test accuracy: 0.993\n"
     ]
    }
   ],
   "source": [
    "epochs = EPOCHS\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 10\n",
    "train_losses, test_losses = [], []\n",
    "\n",
    "t1 = datetime.now()\n",
    "for epoch in range(epochs):\n",
    "    for inputs, labels in trainloader:\n",
    "        steps += 1\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logps = model.forward(inputs)\n",
    "        loss = criterion(logps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if steps % print_every == 0:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in validloader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    logps = model.forward(inputs)\n",
    "                    batch_loss = criterion(logps, labels)\n",
    "                    test_loss += batch_loss.item()\n",
    "                    \n",
    "                    ps = torch.exp(logps)\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "\n",
    "            train_losses.append(running_loss/len(trainloader))\n",
    "            test_losses.append(test_loss/len(validloader))                    \n",
    "            print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "                  f\"Train loss: {running_loss/print_every:.3f}.. \"\n",
    "                  f\"Test loss: {test_loss/len(validloader):.3f}.. \"\n",
    "                  f\"Test accuracy: {accuracy/len(validloader):.3f}\")\n",
    "            running_loss = 0\n",
    "            model.train()\n",
    "t2 = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "XC3Kyoe2qk_J",
    "outputId": "fb336484-8c0d-444b-9d71-743701e8e1ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time: 2019-10-01 22:13:57.895647\n",
      "Finishing time: 2019-10-01 22:19:00.759385\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.859375\n"
     ]
    }
   ],
   "source": [
    "print(\"Start time: {}\".format(t1))\n",
    "print(\"Finishing time: {}\".format(t2))\n",
    "\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(test_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.show()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in testloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        logps = model.forward(inputs)\n",
    "        batch_loss = criterion(logps, labels)\n",
    "        test_loss += batch_loss.item()\n",
    "\n",
    "        ps = torch.exp(logps)\n",
    "        top_p, top_class = ps.topk(1, dim=1)\n",
    "        equals = top_class == labels.view(*top_class.shape)\n",
    "        accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Trabalho_deep_colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
